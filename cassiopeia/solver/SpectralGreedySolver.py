"""
This file stores a subclass of GreedySolver, the SpectralGreedySolver. The
inference procedure here extends the "vanilla" Cassiopeia-Greedy, originally
proposed in Jones et al, Genome Biology (2020). After each putative split of
the samples generated by Cassiopeia-Greedy, the hill-climbing procedure from
the SpectralSolver is applied to the partition to optimize the it for the 
modified normalized cut criterion on a similarity graph built from the 
observed mutations in the samples.
"""
import pandas as pd
from typing import Callable, Dict, List, Optional, Tuple, Union

from cassiopeia.solver import GreedySolver
from cassiopeia.solver import graph_utilities
from cassiopeia.solver import dissimilarity_functions
from cassiopeia.solver.missing_data_methods import assign_missing_average


class SpectralGreedySolver(GreedySolver.GreedySolver):
    """
    TODO: Implement FuzzySolver
    TODO: Experiment to find the best default similarity function
    The SpectralGreedySolver implements a top-down algorithm that recursively
    splits the sample set based on the presence, or absence, of the most
    frequent mutation. Additionally, the hill-climbing procedure from the
    SpectralSolver is used to further optimize each split for the normalized
    cut on the similarity graph on the samples. This effectively moves samples
    across the partition so that both sides of partition have higher internal
    similarity in their mutations. Multiple missing data imputation methods are
    included for handling the case when a sample has a missing value on the
    character being split, where presence or absence of the character is
    ambiguous. The user can also specify a missing data method.

    Args:
        character_matrix: A character matrix of observed character states for
            all samples
        missing_char: The character representing missing values
        missing_data_classifier: Takes either a string specifying one of the
            included missing data imputation methods, or a function
            implementing the user-specified missing data method. The default is
            the "average" method.
        meta_data: Any meta data associated with the samples
        priors: Prior probabilities of observing a transition from 0 to any
            state for each character
        prior_function: A function defining a transformation on the priors
            in forming weights to scale frequencies and the contribution of
            each mutation in the similarity graph
        similarity_function: A function that calculates a similarity score
            between two given samples and their observed mutations. The default
            is "hamming_distance_without_missing"
        threshold: A minimum similarity threshold to include an edge in the
            similarity graph

    Attributes:
        character_matrix: The character matrix describing the samples
        missing_char: The character representing missing values
        meta_data: Data table storing meta data for each sample
        priors: Prior probabilities of character state transitions
        tree: The tree built by `self.solve()`. None if `solve` has not been
            called yet
        unique_character_matrix: A character matrix with duplicate rows filtered
            out, converted to a numpy array for efficient indexing
        node_mapping: A mapping of node names to their integer indices in the
            original character matrix, for efficient indexing
        similarity_function: A function that calculates a similarity score
            between two given samples and their observed mutations
        weights: Weights on character/mutation pairs, derived from priors
        threshold: A minimum similarity threshold
    """

    def __init__(
        self,
        character_matrix: pd.DataFrame,
        missing_char: int,
        missing_data_classifier: Callable = None,
        meta_data: Optional[pd.DataFrame] = None,
        priors: Optional[Dict[int, Dict[int, float]]] = None,
        prior_function: Optional[Callable[[float], float]] = None,
        similarity_function: Optional[
            Callable[
                [
                    List[int],
                    List[int],
                    int,
                    Optional[Dict[int, Dict[int, float]]],
                ],
                float,
            ]
        ] = None,
        threshold: Optional[int] = 0,
    ):

        super().__init__(
            character_matrix, missing_char, meta_data, priors, prior_function
        )

        if not missing_data_classifier:
            self.missing_data_classifier = assign_missing_average
        else:
            self.missing_data_classifier = missing_data_classifier
        self.threshold = threshold
        if similarity_function:
            self.similarity_function = similarity_function
        else:
            self.similarity_function = (
                dissimilarity_functions.hamming_similarity_without_missing
            )

    def perform_split(
        self,
        samples: List[int],
    ) -> Tuple[List[int], List[int]]:
        """Performs a partition using both Greedy and Spectral criteria.

        First, uses the most frequent (character, state) pair to split the
        list of samples. In doing so, the procedure makes use of the missing
        data classifier. Then, it optimizes this partition for the normalized
        cut on a similarity graph constructed on the samples using a hill-
        climbing method.

        Args:
            samples: A list of samples, represented as integer indices

        Returns:
            A tuple of lists, representing the left and right partition groups
        """
        mutation_frequencies = self.compute_mutation_frequencies(samples)

        best_frequency = 0
        chosen_character = 0
        chosen_state = 0
        for character in mutation_frequencies:
            for state in mutation_frequencies[character]:
                if state != self.missing_char and state != 0:
                    # Avoid splitting on mutations shared by all samples
                    if (
                        mutation_frequencies[character][state]
                        < len(samples)
                        - mutation_frequencies[character][self.missing_char]
                    ):
                        if self.weights:
                            if (
                                mutation_frequencies[character][state]
                                * self.weights[character][state]
                                > best_frequency
                            ):
                                chosen_character, chosen_state = (
                                    character,
                                    state,
                                )
                                best_frequency = (
                                    mutation_frequencies[character][state]
                                    * self.weights[character][state]
                                )
                        else:
                            if (
                                mutation_frequencies[character][state]
                                > best_frequency
                            ):
                                chosen_character, chosen_state = (
                                    character,
                                    state,
                                )
                                best_frequency = mutation_frequencies[
                                    character
                                ][state]

        if chosen_state == 0:
            return samples, []

        left_set = []
        right_set = []
        missing = []

        for i in samples:
            if (
                self.unique_character_matrix[i][chosen_character]
                == chosen_state
            ):
                left_set.append(i)
            elif (
                self.unique_character_matrix[i][chosen_character]
                == self.missing_char
            ):
                missing.append(i)
            else:
                right_set.append(i)

        left_set, right_set = self.missing_data_classifier(
            self.unique_character_matrix,
            self.missing_char,
            left_set,
            right_set,
            missing,
        )

        G = graph_utilities.construct_similarity_graph(
            self.unique_character_matrix,
            self.missing_char,
            samples,
            similarity_function=self.similarity_function,
            threshold=self.threshold,
            w=self.weights,
        )

        improved_left_set = graph_utilities.spectral_improve_cut(G, left_set)

        improved_right_set = []
        for i in samples:
            if i not in improved_left_set:
                improved_right_set.append(i)

        return improved_left_set, improved_right_set
